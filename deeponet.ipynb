{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DeepONet` class\n",
    "\n",
    "In the following code block, you can find a template for the class `DeepONet` that implements the DeepONet architecture from [1] (see project description). In particular, the architecture is of the form\n",
    "$$\n",
    "\t{\\rm DeepONet}(a,b,x,y) = \\sum_{i=1}^{N} B_i (a,b) \\, T_i (x,y),\n",
    "$$\n",
    "with the \"Branch Net\" $B (a,b)$ and the \"Trunk Net\" $T (x,y)$ being feedforward neural networks; $N$ is a hyper parameter, which is related to the complexity of the model. Therefore, the class `DeepONet` should rely on the previously implemented class `FeedforwardNeuralNetwork`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "class FeedforwardNeuralNetwork:\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        \"\"\"\n",
    "        Initialize the feedforward neural network.\n",
    "        \n",
    "        Parameters:\n",
    "        layer_sizes (list): List containing the number of neurons in each layer.\n",
    "        \"\"\"\n",
    "\n",
    "        # Layer sizes include input and output layer sizes \n",
    "        self.layer_sizes = layer_sizes  \n",
    "        self.num_layers = len(layer_sizes)\n",
    "        \n",
    "        # Initialize weights and biases with empty arrays\n",
    "        # We use np.array instead of lists as later it will facilitate update operations\n",
    "        self.weights = np.empty( (self.num_layers-1, ), dtype=object)\n",
    "        self.biases = np.empty( (self.num_layers-2, ), dtype=object)\n",
    "        \n",
    "        # Loop through the hidden layers\n",
    "        for l in range(1,self.num_layers-1):    \n",
    "            \n",
    "            # Initialize the weights with uniform distribution, as seen in the lecture notes\n",
    "            self.weights[l-1] = np.random.uniform( -1/np.sqrt(layer_sizes[l]), +1/np.sqrt(layer_sizes[l]) ,size=(layer_sizes[l], layer_sizes[l-1]))\n",
    "\n",
    "            # Initialize biases at zero\n",
    "            self.biases[l-1] = np.zeros((layer_sizes[l],1))\n",
    "\n",
    "        # Last weights (matrix A)\n",
    "        self.weights[-1] = np.random.uniform( -1/np.sqrt(layer_sizes[-2]), +1/np.sqrt(layer_sizes[-2]), size=(layer_sizes[-1], layer_sizes[-2]))\n",
    "        \n",
    "    def activation(self, z):\n",
    "        \"\"\"\n",
    "        Activation function.\n",
    "        \n",
    "        Parameters:\n",
    "        z (numpy.ndarray): Input array.\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray: Output array after applying the activation function.\n",
    "        \"\"\"\n",
    "        # By default use ReLU activation. The activation function can be however replaced by \n",
    "        # assigning self.activation to a different function\n",
    "        return z * (z > 0) # ReLU\n",
    "\n",
    "    def activation_derivative(self, z):\n",
    "        \"\"\"\n",
    "        Derivative of the activation function.\n",
    "        \n",
    "        Parameters:\n",
    "        z (numpy.ndarray): Input array.\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray: Output array after applying derivative of the activation function.\n",
    "        \"\"\"\n",
    "\n",
    "        # Derivative of ReLU\n",
    "        return 1. * (z > 0) \n",
    "\n",
    "    def feedforward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a feedforward pass through the network.\n",
    "        \n",
    "        Parameters:\n",
    "        x (numpy.ndarray): Input array.\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray: Output of the network.\n",
    "        \"\"\"\n",
    "\n",
    "        # x is a single datapoint. Make sure it has the right dimensions and reshape to a column vector\n",
    "        x = x.reshape((len(x), 1))\n",
    "\n",
    "        # save activations of layers (a) for backpropagation\n",
    "        self.a = [ x ]\n",
    "\n",
    "        # save weighted inputs of layers (z) for backpropagation\n",
    "        self.z = []       \n",
    "        \n",
    "        # Loop through the hidden layers\n",
    "        for l in range(1,self.num_layers-1):\n",
    "\n",
    "            # Compute and save z^(l) = W^(l)*a^(l-1) + b^(l)\n",
    "            self.z.append( self.weights[l-1] @ self.a[-1] + self.biases[l-1] ) \n",
    "\n",
    "            # Compute and save a^(l) = activation(z^(l))\n",
    "            self.a.append( self.activation(self.z[-1]))\n",
    "            \n",
    "        #Lastly, multiply by matrix A and return\n",
    "        return self.weights[-1] @ self.a[-1]\n",
    "\n",
    "    def compute_cost(self, y_pred, y_train):\n",
    "        \"\"\"\n",
    "        Compute the cost function.\n",
    "        \n",
    "        Parameters:\n",
    "        y_pred (numpy.ndarray): Predicted labels.\n",
    "        y_train (numpy.ndarray): True labels.\n",
    "        \n",
    "        Returns:\n",
    "        float: Cost value.\n",
    "        \"\"\"\n",
    "        # At every epoch compute loss on the whole dataset\n",
    "        # MSE Loss\n",
    "        return ((y_pred - y_train)**2).sum()/y_pred.shape[0]\n",
    "    \n",
    "    def backpropagate(self, x, error,verbose=False):\n",
    "        \"\"\"\n",
    "        Perform backpropagation to compute gradients.\n",
    "        \n",
    "        Parameters:\n",
    "        x (numpy.ndarray): Input array.\n",
    "        error (numpy.ndarray): Error array.\n",
    "        \n",
    "        Returns:\n",
    "        tuple: Gradients of weights and biases.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the quantity d^(L) := dC/dz^(L)\n",
    "        d = ( 2*error.transpose() @ self.weights[-1]) * self.activation_derivative(self.z[-1]).transpose()\n",
    "\n",
    "        # Initialize the gradient arrays for weights and biases\n",
    "        # Compute and add the gradients for the last layer\n",
    "        nabla_w = [ d.transpose() @ self.a[-2].transpose()]\n",
    "        nabla_b = [ d.transpose() ]\n",
    "\n",
    "        # Loop through the hidden layers except for the last one, for which we have already computed the gradients\n",
    "        for l in reversed(range(1,self.num_layers-2)):\n",
    "\n",
    "            # Compute the quantity d^(l) := dMSE/dz^(l) using the recursive formula that involves d^(l+1)\n",
    "            d = (d @ self.weights[l - 1 + 1]) * self.activation_derivative(self.z[l-1]).transpose()\n",
    "\n",
    "            # Compute gradients for the current layer and save to array\n",
    "            nabla_w.insert(0, d.transpose() @ self.a[l-1].transpose()) \n",
    "            nabla_b.insert(0, d.transpose())\n",
    "\n",
    "        # Compute the gradient of the matrix A\n",
    "        nabla_w.append( 2*error @ self.a[-1].transpose())  \n",
    "\n",
    "        # Transform the lists into numpy arrays, as later it will facilitate update operations\n",
    "        grads_w = np.empty( (len(nabla_w),), dtype=object)\n",
    "        grads_b = np.empty( (len(nabla_b),), dtype=object)\n",
    "        grads_w[...] = nabla_w\n",
    "        grads_b[...] = nabla_b\n",
    "\n",
    "        # return gradients arrays\n",
    "        return (grads_w, grads_b)\n",
    "     \n",
    "    def update_parameters(self, nabla_w, nabla_b, learning_rate, beta, zeta):\n",
    "        \"\"\"\n",
    "        Update the weights and biases using the computed gradients.\n",
    "        \n",
    "        Parameters:\n",
    "        nabla_w (np.ndarray (dtype=object)): Gradients of weights.\n",
    "        nabla_b (np.ndarray (dtype=object)): Gradients of biases.\n",
    "        learning_rate (float): Learning rate.\n",
    "        beta (float): Beta parameter (ADAM)\n",
    "        zeta (float): Zeta parameter (ADAM)\n",
    "        \"\"\"\n",
    " \n",
    "        # Implementation of ADAM, as explained in the lecture notes\n",
    "\n",
    "        # Update u vectors \n",
    "        self.u_w = zeta*self.u_w + (1-zeta)*(nabla_w**2)\n",
    "        self.u_b = zeta*self.u_b + (1-zeta)*(nabla_b**2)\n",
    "\n",
    "        # Update v vectors \n",
    "        self.v_w = beta*self.v_w + (1 - beta)*nabla_w\n",
    "        self.v_b = beta*self.v_b+ (1 - beta)*nabla_b\n",
    "\n",
    "        # Compute alpha^(k)\n",
    "        alpha = learning_rate*np.sqrt(1 - zeta**(self.k+1))/(1 - beta**(self.k+1))\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights -= (alpha/( (self.u_w + 10**(-7))**0.5 ))*nabla_w\n",
    "        self.biases -= (alpha/( (self.u_b + 10**(-7))**0.5 ))*nabla_b\n",
    "\n",
    "        # Update iteration index\n",
    "        self.k += 1\n",
    "\n",
    "    def train(self, x_train, y_train, epochs, learning_rate, batch_size,adam_params=(0.9,0.999),verbose=False):\n",
    "        \"\"\"\n",
    "        Train the neural network using mini-batch gradient descent with early stopping.\n",
    "        \n",
    "        Parameters:\n",
    "        x_train (numpy.ndarray): Training data.\n",
    "        y_train (numpy.ndarray): Training labels.\n",
    "        epochs (int): Number of epochs.\n",
    "        learning_rate (float): Learning rate.\n",
    "        batch_size (int): Size of each mini-batch.\n",
    "        \"\"\"\n",
    "\n",
    "        # Randomly shuffle indices of datapoints\n",
    "        indices = list(range(len(y_train)))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        # Create batches using shuffled indices\n",
    "        batches = [\n",
    "            (x_train[i:i + batch_size], y_train[i:i + batch_size]) \n",
    "            for i in range(0, len(indices), batch_size)\n",
    "        ]\n",
    "\n",
    "        # Initialize ADAM parameters\n",
    "        self.k = 0\n",
    "        self.u_w = np.zeros( (len(self.weights), ), dtype=object)\n",
    "        self.u_b = np.zeros( (len(self.biases), ), dtype=object) \n",
    "        self.v_w = np.zeros( (len(self.weights), ), dtype=object)\n",
    "        self.v_b = np.zeros( (len(self.biases), ), dtype=object)\n",
    "\n",
    "        # Initialize losses vector\n",
    "        losses = []\n",
    "\n",
    "        # Iterate through epochs\n",
    "        # One epoch is defined as the number of steps until all training data has been used once\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # Use all training data, perform one step for each batch\n",
    "            for b in range(len(batches)):\n",
    "\n",
    "                # Select the current batch\n",
    "                x_batch, y_batch = batches[b%len(batches)]\n",
    "            \n",
    "                # Initialize grad variables\n",
    "                nabla_w = np.zeros( (len(self.weights),), dtype=object)\n",
    "                nabla_b = np.zeros( (len(self.biases),), dtype=object)\n",
    "\n",
    "                # Iterate through the datapoints in the batch\n",
    "                for i in range(len(x_batch)):\n",
    "        \n",
    "                    # Perform feedforward and compute error\n",
    "                    error = self.feedforward(x_batch[i]) - y_batch[i]\n",
    "\n",
    "                    # Perform backpropagation and compute partial gradients \n",
    "                    p_nabla_w, p_nabla_b = self.backpropagate(x_batch[i], error)\n",
    "\n",
    "                    # Add partial gradients to final gradients. The resulting\n",
    "                    # gradients nabla_w, nabla_b are the gradients of the MSE \n",
    "                    # loss of the batch\n",
    "                    nabla_w += p_nabla_w/float(x_batch.shape[0])\n",
    "                    nabla_b += p_nabla_b/float(x_batch.shape[0])\n",
    "            \n",
    "                #Update parameters\n",
    "                self.update_parameters(nabla_w,nabla_b,learning_rate, adam_params[0], adam_params[1])\n",
    "\n",
    "            #Make predictions on the whole dataset\n",
    "            y_pred = np.zeros(y_train.shape)\n",
    "            for i in range(len(x_train)):\n",
    "                y_pred[i] = self.feedforward(x_train[i])\n",
    "\n",
    "            # Compute loss on the whole dataset and print it\n",
    "            cost = self.compute_cost(y_pred, y_train)\n",
    "            losses.append(cost)\n",
    "\n",
    "            if(verbose):\n",
    "                print(\"Epoch: {}/{} |  Cost: {}\".format(epoch,epochs,cost))\n",
    "\n",
    "        return losses\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONet:\n",
    "    def __init__(self, branch_layer_sizes, trunk_layer_sizes):\n",
    "        \"\"\"\n",
    "        Initialize the DeepONet architecture.\n",
    "        \n",
    "        Parameters:\n",
    "        branch_layer_sizes (list): List containing the number of neurons in each layer for the branch net.\n",
    "        trunk_layer_sizes (list): List containing the number of neurons in each layer for the trunk net.\n",
    "        \"\"\"\n",
    "        self.branch_net = FeedforwardNeuralNetwork(branch_layer_sizes)\n",
    "        self.trunk_net = FeedforwardNeuralNetwork(trunk_layer_sizes)\n",
    "\n",
    "        sigmoid = lambda z : 1/(1 + np.exp(-z))\n",
    "        sigmoid_prime = lambda z : sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "        relu = lambda z : z * (z > 0)\n",
    "        relu_prime = lambda z : 1. * (z > 0)\n",
    "\n",
    "        tanh = lambda z : np.tanh(z)\n",
    "        tanh_prime = lambda z : 1 - np.tanh(z)**2\n",
    "\n",
    "        self.branch_net.activation = relu\n",
    "        self.branch_net.activation_derivative = relu_prime\n",
    "\n",
    "        self.trunk_net.activation = relu\n",
    "        self.trunk_net.activation_derivative = relu_prime     \n",
    "        \n",
    "        # Ensure the output dimensions of the branch and trunk nets match\n",
    "        assert branch_layer_sizes[-1] == trunk_layer_sizes[-1], \"Output dimensions of branch and trunk nets must match\"\n",
    "\n",
    "    def feedforward(self, x_branch, x_trunk):\n",
    "        \"\"\"\n",
    "        Perform a feedforward pass through the DeepONet.\n",
    "        \n",
    "        Parameters:\n",
    "        x_branch (numpy.ndarray): Input array for the branch net.\n",
    "        x_trunk (numpy.ndarray): Input array for the trunk net.\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray: Output of the DeepONet.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!\n",
    "\n",
    "        return (self.branch_net.feedforward(x_branch)*self.trunk_net.feedforward(x_trunk) ).sum()\n",
    "\n",
    "    def compute_cost(self, y_pred, y_train):\n",
    "        \"\"\"\n",
    "        Compute the cost function.\n",
    "        \n",
    "        Parameters:\n",
    "        y_pred (numpy.ndarray): Predicted labels.\n",
    "        y_train (numpy.ndarray): True labels.\n",
    "        \n",
    "        Returns:\n",
    "        float: Cost value.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!\n",
    "\n",
    "        # Use MSE Loss\n",
    "        return ((y_pred - y_train)**2).sum()/y_pred.shape[0]\n",
    "\n",
    "    def backpropagate(self, x_branch, x_trunk, y):\n",
    "        \"\"\"\n",
    "        Perform backpropagation to compute gradients.\n",
    "        \n",
    "        Parameters:\n",
    "        x_branch (numpy.ndarray): Input array for the branch net.\n",
    "        x_trunk (numpy.ndarray): Input array for the trunk net.\n",
    "        y (numpy.ndarray): True labels.\n",
    "        \n",
    "        Returns:\n",
    "        tuple: Gradients of weights and biases for both branch and trunk nets.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!\n",
    "\n",
    "        T = self.trunk_net.feedforward(x_trunk)\n",
    "        B = self.branch_net.feedforward(x_branch)\n",
    "        error = (T*B).sum() - y\n",
    "\n",
    "        nabla_w_branch, nabla_b_branch = self.branch_net.backpropagate(x_branch, error*T)\n",
    "        nabla_w_trunk, nabla_b_trunk = self.trunk_net.backpropagate(x_trunk, error*B)\n",
    "\n",
    "        return (nabla_w_branch, nabla_b_branch, nabla_w_trunk, nabla_b_trunk)\n",
    "        \n",
    "    def update_parameters(self, nabla_w_branch, nabla_b_branch, nabla_w_trunk, nabla_b_trunk, learning_rate, beta, zeta):\n",
    "        \"\"\"\n",
    "        Update the weights and biases using the computed gradients.\n",
    "        \n",
    "        Parameters:\n",
    "        nabla_w_branch (list): Gradients of weights for the branch net.\n",
    "        nabla_b_branch (list): Gradients of biases for the branch net.\n",
    "        nabla_w_trunk (list): Gradients of weights for the trunk net.\n",
    "        nabla_b_trunk (list): Gradients of biases for the trunk net.\n",
    "        learning_rate (float): Learning rate.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!\n",
    "\n",
    "        self.branch_net.update_parameters(nabla_w_branch, nabla_b_branch, learning_rate, beta, zeta)\n",
    "        self.trunk_net.update_parameters(nabla_w_trunk, nabla_b_trunk, learning_rate, beta, zeta)\n",
    "\n",
    "    def train(self, x_branch, x_trunk, y_train, epochs, learning_rate, batch_size,verbose=False, adam_params=(0.9,0.999)):\n",
    "        \"\"\"\n",
    "        Train the DeepONet using mini-batch gradient descent optimization with early stopping.\n",
    "        \n",
    "        Parameters:\n",
    "        x_branch (numpy.ndarray): Training data for the branch net.\n",
    "        x_trunk (numpy.ndarray): Training data for the trunk net.\n",
    "        y_train (numpy.ndarray): Training labels.\n",
    "        epochs (int): Number of epochs.\n",
    "        learning_rate (float): Learning rate.\n",
    "        batch_size (int): Size of each mini-batch.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!\n",
    "\n",
    "        #Initialize ADAM parameters for branch net\n",
    "        self.branch_net.k = 0\n",
    "        self.branch_net.u_w = np.zeros( (len(self.branch_net.weights), ), dtype=object)\n",
    "        self.branch_net.u_b = np.zeros( (len(self.branch_net.biases), ), dtype=object) \n",
    "        self.branch_net.v_w = np.zeros( (len(self.branch_net.weights), ), dtype=object)\n",
    "        self.branch_net.v_b = np.zeros( (len(self.branch_net.biases), ), dtype=object)\n",
    "\n",
    "        #Initialize ADAM parameters for trunk net\n",
    "        self.trunk_net.k = 0\n",
    "        self.trunk_net.u_w = np.zeros( (len(self.trunk_net.weights), ), dtype=object)\n",
    "        self.trunk_net.u_b = np.zeros( (len(self.trunk_net.biases), ), dtype=object) \n",
    "        self.trunk_net.v_w = np.zeros( (len(self.trunk_net.weights), ), dtype=object)\n",
    "        self.trunk_net.v_b = np.zeros( (len(self.trunk_net.biases), ), dtype=object)\n",
    "\n",
    "        # Shuffle indices\n",
    "        indices = list(range(len(y_train)))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        # Create batches directly using shuffled indices\n",
    "        batches = [\n",
    "            (x_trunk[i:i + batch_size], x_branch[i:i + batch_size], y_train[i:i + batch_size]) \n",
    "            for i in range(0, len(indices), batch_size)\n",
    "        ]\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for b in range(len(batches)):\n",
    "\n",
    "                # Select current batch\n",
    "                x_batch_branch, x_batch_trunk, y_batch = batches[b]\n",
    "\n",
    "                # Initialize grad variables\n",
    "                nabla_w_branch = np.zeros( (len(self.branch_net.weights),), dtype=object)\n",
    "                nabla_b_branch = np.zeros( (len(self.branch_net.biases),), dtype=object)\n",
    "                nabla_w_trunk = np.zeros( (len(self.trunk_net.weights),), dtype=object)\n",
    "                nabla_b_trunk = np.zeros( (len(self.trunk_net.biases),), dtype=object)\n",
    "\n",
    "                for i in range(len(x_batch_branch)):\n",
    "\n",
    "                    p_nabla_w_branch, p_nabla_b_branch, p_nabla_w_trunk, p_nabla_b_trunk = self.backpropagate(x_batch_trunk[i], x_batch_branch[i], y_batch[i])\n",
    "\n",
    "                    # Add partial gradients to final gradients\n",
    "                    nabla_w_branch += p_nabla_w_branch/float(x_batch_branch.shape[0])\n",
    "                    nabla_b_branch += p_nabla_b_branch/float(x_batch_branch.shape[0])\n",
    "                    nabla_w_trunk += p_nabla_w_trunk/float(x_batch_branch.shape[0])\n",
    "                    nabla_b_trunk += p_nabla_b_trunk/float(x_batch_branch.shape[0])\n",
    "\n",
    "                # update parameters\n",
    "                self.update_parameters(nabla_w_branch, nabla_b_branch, nabla_w_trunk, nabla_b_trunk,learning_rate, adam_params[0], adam_params[1])\n",
    "\n",
    "            #Make predictions on the whole dataset, then compute cost and print it\n",
    "            y_pred = np.zeros(y_train.shape)\n",
    "            for i in range(len(x_trunk)):\n",
    "                y_pred[i] = self.feedforward(x_branch[i], x_trunk[i])\n",
    "\n",
    "            cost = self.compute_cost(y_pred, y_train)\n",
    "            losses.append(cost)\n",
    "\n",
    "            if(verbose):    \n",
    "                print(\"Epoch: {}/{} |  Cost: {}\".format(epoch,epochs,cost))\n",
    "\n",
    "        return losses\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary testing: fix $a=1$ and $b=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to approximate: sin(pi * x) * sin(pi * y)\n",
    "def target_function(a, b, x, y):\n",
    "    return a*np.sin(np.pi * x) * np.sin(np.pi * y) + b\n",
    "\n",
    "# Generate training data (1000 datapoints)\n",
    "x_trunk = np.random.rand(1000, 2)  # Random samples in [0, 1]\n",
    "x_branch = np.zeros((1000,2))\n",
    "x_branch[:,0] += 1\n",
    "y_train = target_function(1,0, x_trunk[:, 0], x_trunk[:, 1]).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeponet = DeepONet([2,32,32,32,32,32],[2,32,32,32,32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200 |  Cost: 0.0842862433339857\n",
      "Epoch: 1/200 |  Cost: 0.028971098428309933\n",
      "Epoch: 2/200 |  Cost: 0.028010842109255567\n",
      "Epoch: 3/200 |  Cost: 0.02653444006973023\n",
      "Epoch: 4/200 |  Cost: 0.023610790153553385\n",
      "Epoch: 5/200 |  Cost: 0.018216564963917617\n",
      "Epoch: 6/200 |  Cost: 0.011021506697858455\n",
      "Epoch: 7/200 |  Cost: 0.002512984279734797\n",
      "Epoch: 8/200 |  Cost: 0.0005720972607905291\n",
      "Epoch: 9/200 |  Cost: 0.00027867001899627326\n",
      "Epoch: 10/200 |  Cost: 0.0001688494071296387\n",
      "Epoch: 11/200 |  Cost: 0.00011587359563629682\n",
      "Epoch: 12/200 |  Cost: 9.03798904267469e-05\n",
      "Epoch: 13/200 |  Cost: 7.981906237509534e-05\n",
      "Epoch: 14/200 |  Cost: 7.15107933152241e-05\n",
      "Epoch: 15/200 |  Cost: 6.963571006263382e-05\n",
      "Epoch: 16/200 |  Cost: 7.017840153855859e-05\n",
      "Epoch: 17/200 |  Cost: 6.805147973641967e-05\n",
      "Epoch: 18/200 |  Cost: 6.985330218971791e-05\n",
      "Epoch: 19/200 |  Cost: 7.324823069039448e-05\n",
      "Epoch: 20/200 |  Cost: 7.778411195000741e-05\n",
      "Epoch: 21/200 |  Cost: 7.402981275092028e-05\n",
      "Epoch: 22/200 |  Cost: 7.281618159000124e-05\n",
      "Epoch: 23/200 |  Cost: 7.122429337373588e-05\n",
      "Epoch: 24/200 |  Cost: 7.134524177673549e-05\n",
      "Epoch: 25/200 |  Cost: 6.791452185422e-05\n",
      "Epoch: 26/200 |  Cost: 6.550626742789712e-05\n",
      "Epoch: 27/200 |  Cost: 6.369233863606126e-05\n",
      "Epoch: 28/200 |  Cost: 6.268601087335058e-05\n",
      "Epoch: 29/200 |  Cost: 5.942957688339911e-05\n",
      "Epoch: 30/200 |  Cost: 5.73820832978284e-05\n",
      "Epoch: 31/200 |  Cost: 5.518437850970848e-05\n",
      "Epoch: 32/200 |  Cost: 5.464646067344805e-05\n",
      "Epoch: 33/200 |  Cost: 5.338099303524987e-05\n",
      "Epoch: 34/200 |  Cost: 5.262078738836012e-05\n",
      "Epoch: 35/200 |  Cost: 5.181580159889796e-05\n",
      "Epoch: 36/200 |  Cost: 5.06046075547534e-05\n",
      "Epoch: 37/200 |  Cost: 4.944628734597457e-05\n",
      "Epoch: 38/200 |  Cost: 4.853387001599818e-05\n",
      "Epoch: 39/200 |  Cost: 4.70159651716397e-05\n",
      "Epoch: 40/200 |  Cost: 4.6290622648865416e-05\n",
      "Epoch: 41/200 |  Cost: 4.537578804947672e-05\n",
      "Epoch: 42/200 |  Cost: 4.3908226765811966e-05\n",
      "Epoch: 43/200 |  Cost: 4.340092022318672e-05\n",
      "Epoch: 44/200 |  Cost: 4.267444405213263e-05\n",
      "Epoch: 45/200 |  Cost: 4.229112888056627e-05\n",
      "Epoch: 46/200 |  Cost: 4.12933739995899e-05\n",
      "Epoch: 47/200 |  Cost: 3.954674980402943e-05\n",
      "Epoch: 48/200 |  Cost: 3.817708117387346e-05\n",
      "Epoch: 49/200 |  Cost: 3.761922202256242e-05\n",
      "Epoch: 50/200 |  Cost: 3.6835249299918554e-05\n",
      "Epoch: 51/200 |  Cost: 3.6408652603663507e-05\n",
      "Epoch: 52/200 |  Cost: 3.570531568292781e-05\n",
      "Epoch: 53/200 |  Cost: 3.5505960274124906e-05\n",
      "Epoch: 54/200 |  Cost: 3.505871383487128e-05\n",
      "Epoch: 55/200 |  Cost: 3.4751846017220214e-05\n",
      "Epoch: 56/200 |  Cost: 3.449890202528465e-05\n",
      "Epoch: 57/200 |  Cost: 3.423695395214972e-05\n",
      "Epoch: 58/200 |  Cost: 3.3011689594371826e-05\n",
      "Epoch: 59/200 |  Cost: 3.2957056992626286e-05\n",
      "Epoch: 60/200 |  Cost: 3.220743587887446e-05\n",
      "Epoch: 61/200 |  Cost: 3.1981733334164645e-05\n",
      "Epoch: 62/200 |  Cost: 3.153857021913473e-05\n",
      "Epoch: 63/200 |  Cost: 3.110323265880973e-05\n",
      "Epoch: 64/200 |  Cost: 3.07917644686348e-05\n",
      "Epoch: 65/200 |  Cost: 3.0367877511203918e-05\n",
      "Epoch: 66/200 |  Cost: 2.948552969777437e-05\n",
      "Epoch: 67/200 |  Cost: 2.872857457093817e-05\n",
      "Epoch: 68/200 |  Cost: 2.7691861054857392e-05\n",
      "Epoch: 69/200 |  Cost: 2.7215085748804497e-05\n",
      "Epoch: 70/200 |  Cost: 2.6697779907821974e-05\n",
      "Epoch: 71/200 |  Cost: 2.586584282577286e-05\n",
      "Epoch: 72/200 |  Cost: 2.5617412957690093e-05\n",
      "Epoch: 73/200 |  Cost: 2.494781996671103e-05\n",
      "Epoch: 74/200 |  Cost: 2.431218844349568e-05\n",
      "Epoch: 75/200 |  Cost: 2.3995337551620688e-05\n",
      "Epoch: 76/200 |  Cost: 2.3964999696817857e-05\n",
      "Epoch: 77/200 |  Cost: 2.346296241729394e-05\n",
      "Epoch: 78/200 |  Cost: 2.32565587098364e-05\n",
      "Epoch: 79/200 |  Cost: 2.3284446530411363e-05\n",
      "Epoch: 80/200 |  Cost: 2.2891637740005632e-05\n",
      "Epoch: 81/200 |  Cost: 2.2972904021689518e-05\n",
      "Epoch: 82/200 |  Cost: 2.268156242169833e-05\n",
      "Epoch: 83/200 |  Cost: 2.227920854866831e-05\n",
      "Epoch: 84/200 |  Cost: 2.1760199054313636e-05\n",
      "Epoch: 85/200 |  Cost: 2.157403567212764e-05\n",
      "Epoch: 86/200 |  Cost: 2.1492879025361733e-05\n",
      "Epoch: 87/200 |  Cost: 2.135660429546763e-05\n",
      "Epoch: 88/200 |  Cost: 2.1054028281714727e-05\n",
      "Epoch: 89/200 |  Cost: 2.0874378496073005e-05\n",
      "Epoch: 90/200 |  Cost: 2.067831057457608e-05\n",
      "Epoch: 91/200 |  Cost: 2.0475720045642427e-05\n",
      "Epoch: 92/200 |  Cost: 2.027184450175064e-05\n",
      "Epoch: 93/200 |  Cost: 2.0094273303758213e-05\n",
      "Epoch: 94/200 |  Cost: 1.9898424991389576e-05\n",
      "Epoch: 95/200 |  Cost: 1.9773253721875834e-05\n",
      "Epoch: 96/200 |  Cost: 1.941565245396599e-05\n",
      "Epoch: 97/200 |  Cost: 1.9343573681228476e-05\n",
      "Epoch: 98/200 |  Cost: 1.9165446407331033e-05\n",
      "Epoch: 99/200 |  Cost: 1.913617371284755e-05\n",
      "Epoch: 100/200 |  Cost: 1.8740380832353063e-05\n",
      "Epoch: 101/200 |  Cost: 1.828216201167586e-05\n",
      "Epoch: 102/200 |  Cost: 1.8458822614556065e-05\n",
      "Epoch: 103/200 |  Cost: 1.8279077767604607e-05\n",
      "Epoch: 104/200 |  Cost: 1.8168478158736695e-05\n",
      "Epoch: 105/200 |  Cost: 1.750970896368668e-05\n",
      "Epoch: 106/200 |  Cost: 1.712256325026693e-05\n",
      "Epoch: 107/200 |  Cost: 1.697757952821837e-05\n",
      "Epoch: 108/200 |  Cost: 1.6353992973574534e-05\n",
      "Epoch: 109/200 |  Cost: 1.583406798201541e-05\n",
      "Epoch: 110/200 |  Cost: 1.5648205846395874e-05\n",
      "Epoch: 111/200 |  Cost: 1.5422021696866843e-05\n",
      "Epoch: 112/200 |  Cost: 1.5214749480154188e-05\n",
      "Epoch: 113/200 |  Cost: 1.492299851591323e-05\n",
      "Epoch: 114/200 |  Cost: 1.457780895794938e-05\n",
      "Epoch: 115/200 |  Cost: 1.4330489627343757e-05\n",
      "Epoch: 116/200 |  Cost: 1.4030020194162534e-05\n",
      "Epoch: 117/200 |  Cost: 1.4154336761103848e-05\n",
      "Epoch: 118/200 |  Cost: 1.3687363689223287e-05\n",
      "Epoch: 119/200 |  Cost: 1.3587177697632236e-05\n",
      "Epoch: 120/200 |  Cost: 1.3438661607230465e-05\n",
      "Epoch: 121/200 |  Cost: 1.3454911991796703e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdeeponet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_branch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_trunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.00005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[121], line 166\u001b[0m, in \u001b[0;36mDeepONet.train\u001b[0;34m(self, x_branch, x_trunk, y_train, epochs, learning_rate, batch_size, verbose, adam_params)\u001b[0m\n\u001b[1;32m    164\u001b[0m     nabla_w_branch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_nabla_w_branch\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(x_batch_branch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    165\u001b[0m     nabla_b_branch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_nabla_b_branch\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(x_batch_branch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 166\u001b[0m     nabla_w_trunk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_nabla_w_trunk\u001b[38;5;241m/\u001b[39m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_batch_branch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     nabla_b_trunk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_nabla_b_trunk\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(x_batch_branch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# update parameters\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeponet.train(x_branch, x_trunk, y_train,200,0.00005,7,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 100 x 100 test grid\n",
    "testsize = 100\n",
    "\n",
    "# Coordinates of the gridpoints\n",
    "y_coords = x_coords = np.linspace(0, 1, testsize)\n",
    "\n",
    "# Test_dataset\n",
    "x_test = np.array([[x, y] for x in x_coords for y in y_coords])\n",
    "y_test = target_function(1,0,x_test[:,0], x_test[:,1])\n",
    "x_test_branch = np.zeros(x_test.shape); x_test_branch[:,0] += 1\n",
    "# Reshape as a grid\n",
    "y_test_grid = y_test.reshape(testsize, testsize)\n",
    "\n",
    "\n",
    "X, Y = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "ypred = np.zeros(y_test.shape)\n",
    "for i in range(len(ypred)):\n",
    "    ypred[i] = deeponet.feedforward(x_test_branch[i],x_test[i])\n",
    "\n",
    "ypred_grid = ypred.reshape(testsize, testsize)\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# True u(x, y) values\n",
    "c1 = axes[0].contourf(X, Y, y_test_grid, cmap=\"viridis\", levels=30)\n",
    "fig.colorbar(c1, ax=axes[0], label=\"u(x, y)\")\n",
    "axes[0].set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].set_title(\"True u(x, y)\")\n",
    "\n",
    "# Predicted u(x, y) values\n",
    "c2 = axes[1].contourf(X, Y, ypred_grid, cmap=\"viridis\", levels=30)\n",
    "fig.colorbar(c2, ax=axes[1], label=\"u(x, y)\")\n",
    "axes[1].set_xlabel(\"x\")\n",
    "axes[1].set_ylabel(\"y\")\n",
    "axes[1].set_title(\"Predicted u(x, y)\")\n",
    "\n",
    "# Ensure both plots share the same color scale\n",
    "c1.set_clim(vmin=min(y_test.min(), ypred.min()), vmax=max(y_test.max(), ypred.max()))\n",
    "c2.set_clim(vmin=min(y_test.min(), ypred.min()), vmax=max(y_test.max(), ypred.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix $b = 0$ and let $a \\in [-1,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "\n",
    "# Create dataset\n",
    "x_branch = np.zeros((n_samples,2))\n",
    "x_branch[:,0] = np.random.uniform(-1,1,(n_samples,))\n",
    "\n",
    "x_trunk = np.random.uniform(0,1,(n_samples,2))\n",
    "\n",
    "y_train = target_function(x_branch[:,0], 0, x_trunk[:,0], x_trunk[:,1]).reshape(-1,1)\n",
    "\n",
    "#Normalize parameter a\n",
    "x_branch[:,0] = (x_branch[:,0] + 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeponet = DeepONet([2,32,32,32,32],[2,32,32,32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50 |  Cost: 0.049505682013583865\n",
      "Epoch: 1/50 |  Cost: 0.029126875943213174\n",
      "Epoch: 2/50 |  Cost: 0.02857886494934022\n",
      "Epoch: 3/50 |  Cost: 0.02791549340719949\n",
      "Epoch: 4/50 |  Cost: 0.026915909030438865\n",
      "Epoch: 5/50 |  Cost: 0.02528805787315616\n",
      "Epoch: 6/50 |  Cost: 0.02267628027595482\n",
      "Epoch: 7/50 |  Cost: 0.018782059302801465\n",
      "Epoch: 8/50 |  Cost: 0.013831544140964947\n",
      "Epoch: 9/50 |  Cost: 0.007955643182690576\n",
      "Epoch: 10/50 |  Cost: 0.002147377040792839\n",
      "Epoch: 11/50 |  Cost: 0.0007880416539652171\n",
      "Epoch: 12/50 |  Cost: 0.00048819270419217975\n",
      "Epoch: 13/50 |  Cost: 0.00035821928088484523\n",
      "Epoch: 14/50 |  Cost: 0.00027801989724435364\n",
      "Epoch: 15/50 |  Cost: 0.00023268367727539668\n",
      "Epoch: 16/50 |  Cost: 0.00020016463175141118\n",
      "Epoch: 17/50 |  Cost: 0.00018008840957280597\n",
      "Epoch: 18/50 |  Cost: 0.00016733069331962297\n",
      "Epoch: 19/50 |  Cost: 0.00015655681709385422\n",
      "Epoch: 20/50 |  Cost: 0.00014903322094482192\n",
      "Epoch: 21/50 |  Cost: 0.0001424649025910424\n",
      "Epoch: 22/50 |  Cost: 0.00013672075658946022\n",
      "Epoch: 23/50 |  Cost: 0.000130225213321309\n",
      "Epoch: 24/50 |  Cost: 0.00012490502902306775\n",
      "Epoch: 25/50 |  Cost: 0.00012054363793740567\n",
      "Epoch: 26/50 |  Cost: 0.00011651682898387637\n",
      "Epoch: 27/50 |  Cost: 0.00011283897883854852\n",
      "Epoch: 28/50 |  Cost: 0.00010945067347399531\n",
      "Epoch: 29/50 |  Cost: 0.00010605789174338514\n",
      "Epoch: 30/50 |  Cost: 0.0001032241390528769\n",
      "Epoch: 31/50 |  Cost: 0.00010143013217402244\n",
      "Epoch: 32/50 |  Cost: 0.00010009532403727542\n",
      "Epoch: 33/50 |  Cost: 9.83007573642969e-05\n",
      "Epoch: 34/50 |  Cost: 9.704481787963435e-05\n",
      "Epoch: 35/50 |  Cost: 9.608565938642029e-05\n",
      "Epoch: 36/50 |  Cost: 9.504283604748969e-05\n",
      "Epoch: 37/50 |  Cost: 9.359863206832657e-05\n",
      "Epoch: 38/50 |  Cost: 9.273395224512038e-05\n",
      "Epoch: 39/50 |  Cost: 9.220800009779422e-05\n",
      "Epoch: 40/50 |  Cost: 9.146038165343696e-05\n",
      "Epoch: 41/50 |  Cost: 9.108594484588934e-05\n",
      "Epoch: 42/50 |  Cost: 9.007540575425858e-05\n",
      "Epoch: 43/50 |  Cost: 8.990330758281768e-05\n",
      "Epoch: 44/50 |  Cost: 8.915392487615871e-05\n",
      "Epoch: 45/50 |  Cost: 8.790653381956125e-05\n",
      "Epoch: 46/50 |  Cost: 8.8186602571617e-05\n",
      "Epoch: 47/50 |  Cost: 8.824460754014583e-05\n",
      "Epoch: 48/50 |  Cost: 8.761662736017348e-05\n",
      "Epoch: 49/50 |  Cost: 8.755763823364058e-05\n"
     ]
    }
   ],
   "source": [
    "losses = deeponet.train(x_branch, x_trunk, y_train, 50,0.00005,7, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above test training we can see that with the right selection of hyperparameters, the training loss reaches a very low value even after a low number of iterations. We therefore initially perform a coarse grid search, varying the architectures of the networks and their activation functions, while keeping the epochs at a low number (50) and fixing the learning rate, batch size and ADAM parameters. We use the optimal values found in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross validation dataset\n",
    "k_samples = 5000\n",
    "\n",
    "x_branch_cv = np.zeros((k_samples,2))\n",
    "x_branch_cv[:,0] = np.random.uniform(-1,1,(k_samples,))\n",
    "\n",
    "x_trunk_cv = np.random.uniform(0,1,(k_samples,2))\n",
    "\n",
    "y_cv = target_function(x_branch_cv[:,0], 0, x_trunk_cv[:,0], x_trunk_cv[:,1]).reshape(-1, 1)\n",
    "\n",
    "#Normalize parameter a\n",
    "x_branch_cv[:,0] = (x_branch_cv[:,0] + 1)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "ReLu = lambda z : z * (z > 0)\n",
    "ReLu_prime = lambda z : 1.* (z > 0)\n",
    "\n",
    "tan_h = lambda z : (np.exp (2*z) - 1) / (np.exp (2*z) + 1)\n",
    "tan_h_prime = lambda z : 1 - tan_h(z)**2\n",
    "\n",
    "sigmoid = lambda z : 1/(1+np.exp(-z))\n",
    "sigmoid_prime = lambda z : 1 / (1 + np.exp (z))\n",
    "\n",
    "activation_function = [ReLu, tan_h, sigmoid]\n",
    "derivative_activation_function = [ReLu_prime, tan_h_prime, sigmoid_prime]\n",
    "\n",
    "\n",
    "labels_func = ['ReLu', 'tanh', 'sigmoid'] # Labels to keep track in cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network Architecture**\n",
    "\n",
    "We select three different types of architecture with different patterns, but with roughly the same number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architectures         11008               9216                12352\n",
    "architectures = [ [2, 128, 64, 32, 16], [2, 256, 32, 16], [2, 32, 64, 128, 16] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: ReLu Activation trunk: ReLu CV Loss: 7.144106437387678e-05\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: ReLu Activation trunk: ReLu CV Loss: 7.095609684683555e-05\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: ReLu Activation trunk: ReLu CV Loss: 3.3236827648594765e-05\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: ReLu Activation trunk: ReLu CV Loss: 8.30921003882148e-05\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: ReLu Activation trunk: ReLu CV Loss: 6.470079302536495e-05\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: ReLu Activation trunk: ReLu CV Loss: 7.640554861201016e-05\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: ReLu Activation trunk: ReLu CV Loss: 7.577736451773787e-05\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 256, 32, 16] Activation branch: ReLu Activation trunk: ReLu CV Loss: 7.61749238611982e-05\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: ReLu Activation trunk: ReLu CV Loss: 4.859335253914928e-05\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: ReLu Activation trunk: tanh CV Loss: 0.00014759959196961075\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: ReLu Activation trunk: tanh CV Loss: 4.4594194064531453e-05\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: ReLu Activation trunk: tanh CV Loss: 5.351509043923377e-05\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: ReLu Activation trunk: tanh CV Loss: 4.013772309219724e-05\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: ReLu Activation trunk: tanh CV Loss: 6.680060907296746e-05\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: ReLu Activation trunk: tanh CV Loss: 3.0319647471451954e-05\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: ReLu Activation trunk: tanh CV Loss: 4.476291093611269e-05\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 256, 32, 16] Activation branch: ReLu Activation trunk: tanh CV Loss: 1.598696106512239e-05\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: ReLu Activation trunk: tanh CV Loss: 6.806477984523161e-05\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: ReLu Activation trunk: sigmoid CV Loss: 0.00010793677782878964\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: ReLu Activation trunk: sigmoid CV Loss: 7.918832195541598e-05\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: ReLu Activation trunk: sigmoid CV Loss: 3.5623346497718295e-05\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: ReLu Activation trunk: sigmoid CV Loss: 0.00018070834401108271\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: ReLu Activation trunk: sigmoid CV Loss: 2.181573110734389e-05\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: ReLu Activation trunk: sigmoid CV Loss: 5.818643722164323e-05\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: ReLu Activation trunk: sigmoid CV Loss: 1.975753683441255e-05\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 256, 32, 16] Activation branch: ReLu Activation trunk: sigmoid CV Loss: 7.343909097437936e-05\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: ReLu Activation trunk: sigmoid CV Loss: 4.640165041282506e-05\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: tanh Activation trunk: ReLu CV Loss: 0.00019133309342147457\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: tanh Activation trunk: ReLu CV Loss: 0.000196298219904584\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: tanh Activation trunk: ReLu CV Loss: 0.01641402516187666\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: tanh Activation trunk: ReLu CV Loss: 0.0003416757796633811\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: tanh Activation trunk: ReLu CV Loss: 0.00043635526706034024\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: tanh Activation trunk: ReLu CV Loss: 0.028392943660742152\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: tanh Activation trunk: ReLu CV Loss: 0.00045818491052589767\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 256, 32, 16] Activation branch: tanh Activation trunk: ReLu CV Loss: 0.00034545016387188754\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: tanh Activation trunk: ReLu CV Loss: 0.02834367781767205\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: tanh Activation trunk: tanh CV Loss: 0.00033722544600280936\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: tanh Activation trunk: tanh CV Loss: 0.0001917354804765972\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: tanh Activation trunk: tanh CV Loss: 0.02684833003790141\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: tanh Activation trunk: tanh CV Loss: 0.0002165614680138872\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: tanh Activation trunk: tanh CV Loss: 0.0001754547164435383\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: tanh Activation trunk: tanh CV Loss: 0.024726336198556232\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: tanh Activation trunk: tanh CV Loss: 0.0003519257660747225\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 256, 32, 16] Activation branch: tanh Activation trunk: tanh CV Loss: 0.00019192746103537128\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: tanh Activation trunk: tanh CV Loss: 0.027955869582184118\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: tanh Activation trunk: sigmoid CV Loss: 0.00022875760155185044\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: tanh Activation trunk: sigmoid CV Loss: 0.00013017096637647953\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: tanh Activation trunk: sigmoid CV Loss: 0.028287466991688257\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: tanh Activation trunk: sigmoid CV Loss: 0.00019871742369540545\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: tanh Activation trunk: sigmoid CV Loss: 0.0002690877406126719\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: tanh Activation trunk: sigmoid CV Loss: 0.027742780084611354\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: tanh Activation trunk: sigmoid CV Loss: 0.00023791502526599614\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 256, 32, 16] Activation branch: tanh Activation trunk: sigmoid CV Loss: 0.00032073091563337373\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: tanh Activation trunk: sigmoid CV Loss: 0.028348299883596786\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: sigmoid Activation trunk: ReLu CV Loss: 0.028396658013196928\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: sigmoid Activation trunk: ReLu CV Loss: 0.028449523399366433\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: sigmoid Activation trunk: ReLu CV Loss: 0.028409470352169758\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: sigmoid Activation trunk: ReLu CV Loss: 0.02839914154328726\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: sigmoid Activation trunk: ReLu CV Loss: 0.028452758958266145\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: sigmoid Activation trunk: ReLu CV Loss: 0.02847394659385186\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: sigmoid Activation trunk: ReLu CV Loss: 0.028426696231379105\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 256, 32, 16] Activation branch: sigmoid Activation trunk: ReLu CV Loss: 0.028460368808132557\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: sigmoid Activation trunk: ReLu CV Loss: 0.028500925236705915\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: sigmoid Activation trunk: tanh CV Loss: 0.02840286995262486\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: sigmoid Activation trunk: tanh CV Loss: 0.028488169583090577\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: sigmoid Activation trunk: tanh CV Loss: 0.028466387151163265\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: sigmoid Activation trunk: tanh CV Loss: 0.028399523917293685\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: sigmoid Activation trunk: tanh CV Loss: 0.02857158762542518\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: sigmoid Activation trunk: tanh CV Loss: 0.02861838881961181\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: sigmoid Activation trunk: tanh CV Loss: 0.028433409262448684\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 256, 32, 16] Activation branch: sigmoid Activation trunk: tanh CV Loss: 0.02842986732041677\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: sigmoid Activation trunk: tanh CV Loss: 0.028460257036936356\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: sigmoid Activation trunk: sigmoid CV Loss: 0.028396602744946386\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: sigmoid Activation trunk: sigmoid CV Loss: 0.02839637134488702\n",
      "Arch branch: [2, 128, 64, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: sigmoid Activation trunk: sigmoid CV Loss: 0.028449761501706746\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: sigmoid Activation trunk: sigmoid CV Loss: 0.0284858180630828\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 256, 32, 16] Activation branch: sigmoid Activation trunk: sigmoid CV Loss: 0.028399946688380466\n",
      "Arch branch: [2, 256, 32, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: sigmoid Activation trunk: sigmoid CV Loss: 0.0284323281911932\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 128, 64, 32, 16] Activation branch: sigmoid Activation trunk: sigmoid CV Loss: 0.028467215206684215\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 256, 32, 16] Activation branch: sigmoid Activation trunk: sigmoid CV Loss: 0.02845124565896619\n",
      "Arch branch: [2, 32, 64, 128, 16] Arch trunk: [2, 32, 64, 128, 16] Activation branch: sigmoid Activation trunk: sigmoid CV Loss: 0.02842940090947825\n"
     ]
    }
   ],
   "source": [
    "for act_b in range(len(activation_function)):\n",
    "\n",
    "    for act_t in range(len(activation_function)):\n",
    "\n",
    "        for arch_b in architectures:\n",
    "\n",
    "            for arch_t in architectures:\n",
    "\n",
    "                deeponet = DeepONet(arch_b, arch_t)\n",
    "\n",
    "                deeponet.branch_net.activation = activation_function[act_b]\n",
    "                deeponet.branch_net.activation_derivative = derivative_activation_function[act_b]\n",
    "\n",
    "                deeponet.trunk_net.activation = activation_function[act_b]\n",
    "                deeponet.trunk_net.activation_derivative = derivative_activation_function[act_b]\n",
    "\n",
    "                deeponet.train(x_branch, x_trunk, y_train, 50, 0.00005,5)\n",
    "\n",
    "                y_pred = np.zeros((k_samples,1))\n",
    "                for j in range(k_samples):\n",
    "                    y_pred[j] = deeponet.feedforward(x_branch_cv[j,:], x_trunk_cv[j,:])\n",
    "\n",
    "                loss = deeponet.compute_cost(y_pred,y_cv)\n",
    "\n",
    "                print(\"Arch branch: {} Arch trunk: {} Activation branch: {} Activation trunk: {} CV Loss: {}\".format(arch_b, arch_t, labels_func[act_b], labels_func[act_t], loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the grid search, the best combination of architectures and activation functions is \n",
    "\n",
    "- Branch architecture: [2, 32, 64, 128, 16]\n",
    "- Trunk architecture: [2, 256, 32, 16]\n",
    "- Branch activation function: ReLu\n",
    "- Trunk activation function: Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.0001, 0.00005, 0.00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [ int(n_samples**(1/3)), int(n_samples**(2/3)), n_samples ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [0.9, 0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "zetas = [0.999, 0.95]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to use 50 epochs because already with this number of epochs the loss is already low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Learning rate: 0.0001 Batch size: 21 Beta: 0.9 Zeta: 0.999 Loss: 0.0003377146957874848\n",
      " Learning rate: 0.0001 Batch size: 21 Beta: 0.9 Zeta: 0.95 Loss: 0.00013948151699308173\n",
      " Learning rate: 0.0001 Batch size: 21 Beta: 0.85 Zeta: 0.999 Loss: 0.0003319070578308209\n",
      " Learning rate: 0.0001 Batch size: 21 Beta: 0.85 Zeta: 0.95 Loss: 0.00022630394142027352\n",
      " Learning rate: 0.0001 Batch size: 464 Beta: 0.9 Zeta: 0.999 Loss: 0.029093686338897647\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m deeponet\u001b[38;5;241m.\u001b[39mtrunk_net\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m tan_h\n\u001b[1;32m     16\u001b[0m deeponet\u001b[38;5;241m.\u001b[39mtrunk_net\u001b[38;5;241m.\u001b[39mactivation_derivative \u001b[38;5;241m=\u001b[39m tan_h_prime\n\u001b[0;32m---> 18\u001b[0m \u001b[43mdeeponet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_branch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_trunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43madam_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mzeta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((k_samples,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_samples):\n",
      "Cell \u001b[0;32mIn[121], line 165\u001b[0m, in \u001b[0;36mDeepONet.train\u001b[0;34m(self, x_branch, x_trunk, y_train, epochs, learning_rate, batch_size, verbose, adam_params)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Add partial gradients to final gradients\u001b[39;00m\n\u001b[1;32m    164\u001b[0m nabla_w_branch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_nabla_w_branch\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(x_batch_branch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 165\u001b[0m nabla_b_branch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_nabla_b_branch\u001b[38;5;241m/\u001b[39m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_batch_branch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m nabla_w_trunk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_nabla_w_trunk\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(x_batch_branch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m nabla_b_trunk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_nabla_b_trunk\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(x_batch_branch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "combinations = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "\n",
    "    for bs in batch_sizes:\n",
    "\n",
    "        for beta in betas:\n",
    "\n",
    "            for zeta in zetas:\n",
    "\n",
    "                deeponet = DeepONet([2, 32, 64, 128, 16], [2, 256, 32, 16])\n",
    "\n",
    "                deeponet.trunk_net.activation = tan_h\n",
    "                deeponet.trunk_net.activation_derivative = tan_h_prime\n",
    "\n",
    "                deeponet.train(x_branch, x_trunk, y_train, 50, lr,bs,verbose=False,adam_params=(beta,zeta))\n",
    "\n",
    "                y_pred = np.zeros((k_samples,1))\n",
    "                for j in range(k_samples):\n",
    "                    y_pred[j] = deeponet.feedforward(x_branch_cv[j,:], x_trunk_cv[j,:])\n",
    "\n",
    "                loss = deeponet.compute_cost(y_pred,y_cv)\n",
    "                print(\" Learning rate: {} Batch size: {} Beta: {} Zeta: {} Loss: {}\".format(lr,bs,beta,zeta,loss))\n",
    "\n",
    "                combinations.append( (lr, bs, beta, zeta, loss))\n",
    "\n",
    "\n",
    "pickle.dump(combinations, open(\"combinations_deeponet.dat\",\"wb\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this grid search we can conclude that the optimal parameters are: \n",
    "\n",
    "- Learning rate: 0.0001\n",
    "- Batch size: 21\n",
    "- $\\beta$ : 0.85\n",
    "- $\\zeta$ : 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test the model for unseen values of a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test set\n",
    "m_samples = 5000\n",
    "\n",
    "x_branch_test = np.zeros((m_samples,2))\n",
    "x_branch_test[:,0] = np.random.uniform(-1,1,(m_samples,))\n",
    "\n",
    "x_trunk_test = np.random.uniform(0,1,(m_samples,2))\n",
    "\n",
    "y_test = target_function(x_branch_test[:,0], 0, x_trunk_test[:,0], x_trunk_test[:,1]).reshape(-1, 1)\n",
    "\n",
    "#Normalize parameter a\n",
    "x_branch_test[:,0] = (x_branch_test[:,0] + 1)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50 |  Cost: 0.08311113013058659\n",
      "Epoch: 1/50 |  Cost: 0.028838611542446005\n",
      "Epoch: 2/50 |  Cost: 0.02759249058859222\n",
      "Epoch: 3/50 |  Cost: 0.025804426136049892\n",
      "Epoch: 4/50 |  Cost: 0.022681830080576074\n",
      "Epoch: 5/50 |  Cost: 0.016840721814603016\n",
      "Epoch: 6/50 |  Cost: 0.008963798173241451\n",
      "Epoch: 7/50 |  Cost: 0.002186573304730636\n",
      "Epoch: 8/50 |  Cost: 0.0008243186125759601\n",
      "Epoch: 9/50 |  Cost: 0.0004799509254633695\n",
      "Epoch: 10/50 |  Cost: 0.00030965446357614457\n",
      "Epoch: 11/50 |  Cost: 0.0002160871967299839\n",
      "Epoch: 12/50 |  Cost: 0.0001610493693670353\n",
      "Epoch: 13/50 |  Cost: 0.00012749102387230022\n",
      "Epoch: 14/50 |  Cost: 0.00010832310898545492\n",
      "Epoch: 15/50 |  Cost: 9.351820016566785e-05\n",
      "Epoch: 16/50 |  Cost: 7.985068354504697e-05\n",
      "Epoch: 17/50 |  Cost: 7.158158222109256e-05\n",
      "Epoch: 18/50 |  Cost: 6.685885869627247e-05\n",
      "Epoch: 19/50 |  Cost: 6.389570823956764e-05\n",
      "Epoch: 20/50 |  Cost: 6.085031382989748e-05\n",
      "Epoch: 21/50 |  Cost: 5.876956608251415e-05\n",
      "Epoch: 22/50 |  Cost: 5.759212069523637e-05\n",
      "Epoch: 23/50 |  Cost: 5.7753808628759175e-05\n",
      "Epoch: 24/50 |  Cost: 5.6795351834286166e-05\n",
      "Epoch: 25/50 |  Cost: 5.6021820641583196e-05\n",
      "Epoch: 26/50 |  Cost: 5.5619126274665634e-05\n",
      "Epoch: 27/50 |  Cost: 5.609672759210691e-05\n",
      "Epoch: 28/50 |  Cost: 5.47918025081886e-05\n",
      "Epoch: 29/50 |  Cost: 5.53406208917406e-05\n",
      "Epoch: 30/50 |  Cost: 5.689490976553623e-05\n",
      "Epoch: 31/50 |  Cost: 5.5408688358493594e-05\n",
      "Epoch: 32/50 |  Cost: 5.3767325032868705e-05\n",
      "Epoch: 33/50 |  Cost: 5.2870669968785135e-05\n",
      "Epoch: 34/50 |  Cost: 5.091892812664025e-05\n",
      "Epoch: 35/50 |  Cost: 5.003667367082816e-05\n",
      "Epoch: 36/50 |  Cost: 4.598529854343646e-05\n",
      "Epoch: 37/50 |  Cost: 4.320417103379009e-05\n",
      "Epoch: 38/50 |  Cost: 4.196243737190415e-05\n",
      "Epoch: 39/50 |  Cost: 3.9561667273730915e-05\n",
      "Epoch: 40/50 |  Cost: 3.8742100001862744e-05\n",
      "Epoch: 41/50 |  Cost: 3.6276957481424356e-05\n",
      "Epoch: 42/50 |  Cost: 3.50709151576718e-05\n",
      "Epoch: 43/50 |  Cost: 3.461348158034022e-05\n",
      "Epoch: 44/50 |  Cost: 3.3341437266945056e-05\n",
      "Epoch: 45/50 |  Cost: 3.244410124216756e-05\n",
      "Epoch: 46/50 |  Cost: 3.188241217791619e-05\n",
      "Epoch: 47/50 |  Cost: 3.070764976816774e-05\n",
      "Epoch: 48/50 |  Cost: 2.9906564794852507e-05\n",
      "Epoch: 49/50 |  Cost: 2.9277791661591196e-05\n"
     ]
    }
   ],
   "source": [
    "deeponet = DeepONet([2, 32, 64, 128, 16], [2, 256, 32, 16])\n",
    "losses = deeponet.train(x_branch, x_trunk, y_train, 50, 0.0001, 21, adam_params=(0.85,0.999),verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.015169119003997e-05 \n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros((m_samples,1))\n",
    "for j in range(m_samples):\n",
    "    y_pred[j] = deeponet.feedforward(x_branch_test[j,:], x_trunk_test[j,:])\n",
    "\n",
    "print(\"Test Loss: {} \".format(deeponet.compute_cost(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to follow the same procedure as in point (b), also varyng $b \\in [-1,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "\n",
    "# Create train dataset\n",
    "x_branch = np.random.uniform(-1,1,(n_samples,2))\n",
    "x_trunk = np.random.uniform(0,1,(n_samples,2))\n",
    "\n",
    "y_train = target_function(x_branch[:,0], x_branch[:,1], x_trunk[:,0], x_trunk[:,1]).reshape(-1,1)\n",
    "\n",
    "#Normalize parameter a and b\n",
    "x_branch[:,0] = (x_branch[:,0] + 1)/2\n",
    "x_branch[:,1] = (x_branch[:,1] + 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_samples = 5000\n",
    "\n",
    "# Create cross-validation dataset\n",
    "x_branch_cv = np.random.uniform(-1,1,(k_samples,2))\n",
    "x_trunk_cv = np.random.uniform(0,1,(k_samples,2))\n",
    "\n",
    "y_cv = target_function(x_branch_cv[:,0], x_branch_cv[:,1], x_trunk_cv[:,0], x_trunk_cv[:,1]).reshape(-1,1)\n",
    "\n",
    "#Normalize parameter a and b\n",
    "x_branch_cv[:,0] = (x_branch_cv[:,0] + 1)/2\n",
    "x_branch_cv[:,1] = (x_branch_cv[:,1] + 1)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use multiprocessing to speed up computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different combinations of architectures and functions\n",
    "combinations = []\n",
    "\n",
    "for act_b in range(len(activation_function)):\n",
    "\n",
    "    for act_t in range(len(activation_function)):\n",
    "\n",
    "        for arch_b in architectures:\n",
    "\n",
    "            for arch_t in architectures:\n",
    "\n",
    "                combinations.append((act_b, act_t, arch_b, arch_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cv_loss(activation_branch, activation_trunk, arch_branch, arch_trunk):\n",
    "\n",
    "    deeponet = DeepONet(arch_branch, arch_trunk)\n",
    "\n",
    "    deeponet.branch_net.activation = activation_function[activation_branch]\n",
    "    deeponet.branch_net.activation_derivative = derivative_activation_function[activation_branch]\n",
    "\n",
    "    deeponet.trunk_net.activation = activation_function[activation_trunk]\n",
    "    deeponet.trunk_net.activation_derivative = derivative_activation_function[activation_trunk]\n",
    "\n",
    "    deeponet.train(x_branch, x_trunk, y_train, 50, 0.00005,5)\n",
    "\n",
    "    y_pred = np.zeros((k_samples,1))\n",
    "    for j in range(k_samples):\n",
    "        y_pred[j] = deeponet.feedforward(x_branch_cv[j,:], x_trunk_cv[j,:])\n",
    "\n",
    "    return deeponet.compute_cost(y_pred,y_cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(comb):\n",
    "    return compute_cv_loss(comb[0],comb[1], comb[2], comb[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "# Run with multiple threads \n",
    "num_cores = os.cpu_count()\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "    results = list(executor.map(worker, combinations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the results, we can see that the loss at index 3 has the lowest value. The same index can be used to see the corresponding combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, [2, 256, 32, 16], [2, 128, 64, 32, 16])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[3]\n",
    "combinations[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this grid search we can conclude that the best combination of architectures and activation functions is \n",
    "\n",
    "Branch network:\n",
    "\n",
    "- Architecture: [2, 256, 32, 16]\n",
    "- Activation: ReLU\n",
    "\n",
    "Trunk network:\n",
    "\n",
    "- Architecture: [2, 128, 64, 32, 16]\n",
    "- Activation: ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( (combinations,results), open(\"combinations_results_c_deeponet.dat\",\"wb\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now perform another grid search for the other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combinations_2 = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "\n",
    "    for bs in batch_sizes:\n",
    "\n",
    "        for beta in betas:\n",
    "\n",
    "            for zeta in zetas:\n",
    "\n",
    "                combinations_2.append( (lr, bs, beta, zeta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cv_loss_2(lr, bs, beta, zeta):\n",
    "\n",
    "    deeponet = DeepONet([2, 256, 32, 16],[2, 128, 64, 32, 16])\n",
    "    deeponet.train(x_branch, x_trunk, y_train, 200, lr, bs,adam_params=(beta,zeta))\n",
    "\n",
    "    y_pred = np.zeros((k_samples,1))\n",
    "    for j in range(k_samples):\n",
    "        y_pred[j] = deeponet.feedforward(x_branch_cv[j,:], x_trunk_cv[j,:])\n",
    "\n",
    "    print(\"Combo done!\")\n",
    "    return deeponet.compute_cost(y_pred,y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_2(comb):\n",
    "    return compute_cv_loss_2(comb[0], comb[1], comb[2], comb[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num cores: 16\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n",
      "Combo done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_cores = os.cpu_count()\n",
    "print(\"Num cores: {}\".format(num_cores))\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "    results = list(executor.map(worker_2, combinations_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(2.050042879357849e-05), (0.0001, 21, 0.9, 0.999))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0], combinations_2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the optimized model has the following hyperparameters:\n",
    "\n",
    "Branch network:\n",
    "\n",
    "- Architecture: [2, 256, 32, 16]\n",
    "- Activation: ReLU\n",
    "\n",
    "Trunk network:\n",
    "\n",
    "- Architecture: [2, 128, 64, 32, 16]\n",
    "- Activation: ReLU\n",
    "\n",
    "- Learning rate; 0.0001\n",
    "- Batch size: 21\n",
    "- $\\beta$ = 0.9\n",
    "- $\\zeta$ = 0.999\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test the model with new unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test set\n",
    "m_samples = 5000\n",
    "\n",
    "\n",
    "x_branch_test = np.random.uniform(-1,1,(m_samples,2))\n",
    "\n",
    "x_trunk_test = np.random.uniform(0,1,(m_samples,2))\n",
    "\n",
    "y_test = target_function(x_branch_test[:,0], x_branch_test[:,1], x_trunk_test[:,0], x_trunk_test[:,1]).reshape(-1, 1)\n",
    "\n",
    "#Normalize parameter a and b\n",
    "x_branch_test = (x_branch_test + 1)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50 |  Cost: 0.04259212457506461\n",
      "Epoch: 1/50 |  Cost: 0.03303604451509947\n",
      "Epoch: 2/50 |  Cost: 0.029310045121645204\n",
      "Epoch: 3/50 |  Cost: 0.02828181833947223\n",
      "Epoch: 4/50 |  Cost: 0.027683087035619332\n",
      "Epoch: 5/50 |  Cost: 0.027197525882567197\n",
      "Epoch: 6/50 |  Cost: 0.026733233527711297\n",
      "Epoch: 7/50 |  Cost: 0.026317001940016668\n",
      "Epoch: 8/50 |  Cost: 0.025937633902148018\n",
      "Epoch: 9/50 |  Cost: 0.025598667468257272\n",
      "Epoch: 10/50 |  Cost: 0.02531066911183461\n",
      "Epoch: 11/50 |  Cost: 0.025045102409673253\n",
      "Epoch: 12/50 |  Cost: 0.024798274467986353\n",
      "Epoch: 13/50 |  Cost: 0.024542130244404558\n",
      "Epoch: 14/50 |  Cost: 0.024216964813326986\n",
      "Epoch: 15/50 |  Cost: 0.02374307512687994\n",
      "Epoch: 16/50 |  Cost: 0.022898868380135797\n",
      "Epoch: 17/50 |  Cost: 0.020859132226179633\n",
      "Epoch: 18/50 |  Cost: 0.015798228007540546\n",
      "Epoch: 19/50 |  Cost: 0.006230596779570239\n",
      "Epoch: 20/50 |  Cost: 0.0009589140150906094\n",
      "Epoch: 21/50 |  Cost: 0.0005109702873602413\n",
      "Epoch: 22/50 |  Cost: 0.00036948911149200207\n",
      "Epoch: 23/50 |  Cost: 0.00029281426107933417\n",
      "Epoch: 24/50 |  Cost: 0.00027899187967077554\n",
      "Epoch: 25/50 |  Cost: 0.0002877900942178965\n",
      "Epoch: 26/50 |  Cost: 0.00031077864099237875\n",
      "Epoch: 27/50 |  Cost: 0.00032742793227978834\n",
      "Epoch: 28/50 |  Cost: 0.00033792602254249007\n",
      "Epoch: 29/50 |  Cost: 0.0003405657763574699\n",
      "Epoch: 30/50 |  Cost: 0.000341294631561439\n",
      "Epoch: 31/50 |  Cost: 0.00035319827679601004\n",
      "Epoch: 32/50 |  Cost: 0.0003499819208063756\n",
      "Epoch: 33/50 |  Cost: 0.00032844521977540444\n",
      "Epoch: 34/50 |  Cost: 0.00032666504532414035\n",
      "Epoch: 35/50 |  Cost: 0.0003263380721322688\n",
      "Epoch: 36/50 |  Cost: 0.00032788076329929563\n",
      "Epoch: 37/50 |  Cost: 0.0003297114530781335\n",
      "Epoch: 38/50 |  Cost: 0.0003338548628316689\n",
      "Epoch: 39/50 |  Cost: 0.0003254972181033034\n",
      "Epoch: 40/50 |  Cost: 0.0003141798349178476\n",
      "Epoch: 41/50 |  Cost: 0.00031033634486665957\n",
      "Epoch: 42/50 |  Cost: 0.00031980563199019915\n",
      "Epoch: 43/50 |  Cost: 0.00031635443399587003\n",
      "Epoch: 44/50 |  Cost: 0.0003284512215673585\n",
      "Epoch: 45/50 |  Cost: 0.0003279223998596642\n",
      "Epoch: 46/50 |  Cost: 0.00032610253610049325\n",
      "Epoch: 47/50 |  Cost: 0.0003136722367766806\n",
      "Epoch: 48/50 |  Cost: 0.0002933352009710575\n",
      "Epoch: 49/50 |  Cost: 0.00027655183165429766\n"
     ]
    }
   ],
   "source": [
    "deeponet = DeepONet([2, 256, 32, 16], [2, 128, 64, 32,16])\n",
    "losses = deeponet.train(x_branch, x_trunk, y_train, 50, 0.0001, 21, adam_params=(0.85,0.999),verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0002970545738821036 \n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros((m_samples,1))\n",
    "for j in range(m_samples):\n",
    "    y_pred[j] = deeponet.feedforward(x_branch_test[j,:], x_trunk_test[j,:])\n",
    "\n",
    "print(\"Test Loss: {} \".format(deeponet.compute_cost(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
